{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_classification_tf.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_3B5c7l4_42"
      },
      "source": [
        "#NN for classification\n",
        "#Classification problem \n",
        "binary\n",
        "\n",
        "multiclass\n",
        "\n",
        "multilabel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-k-oj_y5VYg"
      },
      "source": [
        "from sklearn.datasets import make_circles\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVfuRutP54SG"
      },
      "source": [
        "n_samples=1000\n",
        "X,y=make_circles(n_samples,noise=0.03,\n",
        "                 random_state=42)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2o6L1Vd579M",
        "outputId": "d0535787-def4-4c4c-935b-006a233dd011"
      },
      "source": [
        "X[:10]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.75424625,  0.23148074],\n",
              "       [-0.75615888,  0.15325888],\n",
              "       [-0.81539193,  0.17328203],\n",
              "       [-0.39373073,  0.69288277],\n",
              "       [ 0.44220765, -0.89672343],\n",
              "       [-0.47964637,  0.67643477],\n",
              "       [-0.01364836,  0.80334872],\n",
              "       [ 0.77151327,  0.14775959],\n",
              "       [-0.16932234, -0.79345575],\n",
              "       [-0.1214858 ,  1.02150905]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBjWVjaf6LPT",
        "outputId": "e99ef9a2-0eff-4250-f993-1f432f78e0f0"
      },
      "source": [
        "y[:10]"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 0, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvMcc0wT6MzO"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6MGXv-A7S6h"
      },
      "source": [
        "circles=pd.DataFrame({\"x0\":X[:,0],\"x1\":X[:,1],\"y\":y})"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "LLSM62tu7S9l",
        "outputId": "f4221af9-2ac2-4197-a0fd-060e56e7c266"
      },
      "source": [
        "circles"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x0</th>\n",
              "      <th>x1</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.754246</td>\n",
              "      <td>0.231481</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.756159</td>\n",
              "      <td>0.153259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.815392</td>\n",
              "      <td>0.173282</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.393731</td>\n",
              "      <td>0.692883</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.442208</td>\n",
              "      <td>-0.896723</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>0.244054</td>\n",
              "      <td>0.944125</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>-0.978655</td>\n",
              "      <td>-0.272373</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>-0.136900</td>\n",
              "      <td>-0.810012</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>0.670362</td>\n",
              "      <td>-0.767502</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>0.281057</td>\n",
              "      <td>0.963824</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           x0        x1  y\n",
              "0    0.754246  0.231481  1\n",
              "1   -0.756159  0.153259  1\n",
              "2   -0.815392  0.173282  1\n",
              "3   -0.393731  0.692883  1\n",
              "4    0.442208 -0.896723  0\n",
              "..        ...       ... ..\n",
              "995  0.244054  0.944125  0\n",
              "996 -0.978655 -0.272373  0\n",
              "997 -0.136900 -0.810012  1\n",
              "998  0.670362 -0.767502  0\n",
              "999  0.281057  0.963824  0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "z7C18dyv7TA-",
        "outputId": "8384d303-f8bd-438f-de51-663a6f937614"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X[:,0],X[:,1])\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f0c9709c690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHvHDQTR7TOW",
        "outputId": "98be0c26-5eb8-493e-fd19-96e3ef2cd879"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TML1P0S26M2U",
        "outputId": "343285e3-e0c1-4634-da7e-a8ffe5950334"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYmlUYGU6M5i",
        "outputId": "9ca6ce44-7021-4037-d265-68f4cbc395a1"
      },
      "source": [
        "len(X),len(y)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJg30gMO-n6Q",
        "outputId": "a3c7c04a-1d5d-4c23-871c-d1a1003ab43b"
      },
      "source": [
        "X[0]"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.75424625, 0.23148074])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BrKhXU1-n9r",
        "outputId": "3d8666fa-9b0d-4f06-91a9-1138d5a8971a"
      },
      "source": [
        "y[0]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZanx_PT-oAV"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFAZJQVf-wIs"
      },
      "source": [
        "tf.random.set_seed(42)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWYfkxMqAatL"
      },
      "source": [
        "model_1=tf.keras.Sequential([\n",
        "     tf.keras.layers.Dense(1)     \n",
        "    ]\n",
        ")\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVirYtBRAbcr"
      },
      "source": [
        "model_1.compile(optimizer=tf.keras.optimizers.SGD(),\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQCUG9c9AbpR",
        "outputId": "5fc7adef-6b73-490d-c942-df5811c53cd4"
      },
      "source": [
        "model_1.fit(X,y,epochs=500)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 2.8544 - accuracy: 0.4600\n",
            "Epoch 2/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.7131 - accuracy: 0.5430\n",
            "Epoch 3/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6973 - accuracy: 0.5090\n",
            "Epoch 4/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.5010\n",
            "Epoch 5/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4830\n",
            "Epoch 6/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4990\n",
            "Epoch 7/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4880\n",
            "Epoch 8/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4950\n",
            "Epoch 9/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4840\n",
            "Epoch 10/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4820\n",
            "Epoch 11/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4640\n",
            "Epoch 12/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4800\n",
            "Epoch 13/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4830\n",
            "Epoch 14/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5030\n",
            "Epoch 15/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4510\n",
            "Epoch 16/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4880\n",
            "Epoch 17/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4910\n",
            "Epoch 18/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4760\n",
            "Epoch 19/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4820\n",
            "Epoch 20/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4560\n",
            "Epoch 21/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4900\n",
            "Epoch 22/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4690\n",
            "Epoch 23/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4840\n",
            "Epoch 24/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4680\n",
            "Epoch 25/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4890\n",
            "Epoch 26/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4740\n",
            "Epoch 27/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5060\n",
            "Epoch 28/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4690\n",
            "Epoch 29/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4620\n",
            "Epoch 30/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4870\n",
            "Epoch 31/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5230\n",
            "Epoch 32/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4670\n",
            "Epoch 33/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4760\n",
            "Epoch 34/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.4590\n",
            "Epoch 35/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5010\n",
            "Epoch 36/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4710\n",
            "Epoch 37/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5020\n",
            "Epoch 38/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4670\n",
            "Epoch 39/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4350\n",
            "Epoch 40/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.4720\n",
            "Epoch 41/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4730\n",
            "Epoch 42/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4640\n",
            "Epoch 43/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4850\n",
            "Epoch 44/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5080\n",
            "Epoch 45/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4710\n",
            "Epoch 46/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4850\n",
            "Epoch 47/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4940\n",
            "Epoch 48/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4900\n",
            "Epoch 49/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4770\n",
            "Epoch 50/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4980\n",
            "Epoch 51/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4820\n",
            "Epoch 52/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4890\n",
            "Epoch 53/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4690\n",
            "Epoch 54/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4920\n",
            "Epoch 55/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4970\n",
            "Epoch 56/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4800\n",
            "Epoch 57/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4710\n",
            "Epoch 58/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4870\n",
            "Epoch 59/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5030\n",
            "Epoch 60/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5060\n",
            "Epoch 61/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4990\n",
            "Epoch 62/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4760\n",
            "Epoch 63/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4690\n",
            "Epoch 64/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4930\n",
            "Epoch 65/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4690\n",
            "Epoch 66/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4770\n",
            "Epoch 67/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4670\n",
            "Epoch 68/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4680\n",
            "Epoch 69/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5070\n",
            "Epoch 70/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4630\n",
            "Epoch 71/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4820\n",
            "Epoch 72/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4890\n",
            "Epoch 73/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4760\n",
            "Epoch 74/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.5090\n",
            "Epoch 75/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4940\n",
            "Epoch 76/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5010\n",
            "Epoch 77/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4870\n",
            "Epoch 78/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4610\n",
            "Epoch 79/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4860\n",
            "Epoch 80/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5050\n",
            "Epoch 81/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5050\n",
            "Epoch 82/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4690\n",
            "Epoch 83/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4930\n",
            "Epoch 84/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4960\n",
            "Epoch 85/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4930\n",
            "Epoch 86/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4880\n",
            "Epoch 87/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4720\n",
            "Epoch 88/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.4470\n",
            "Epoch 89/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4720\n",
            "Epoch 90/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4820\n",
            "Epoch 91/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4860\n",
            "Epoch 92/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5050\n",
            "Epoch 93/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4720\n",
            "Epoch 94/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.4770\n",
            "Epoch 95/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4760\n",
            "Epoch 96/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4610\n",
            "Epoch 97/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4690\n",
            "Epoch 98/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4840\n",
            "Epoch 99/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4980\n",
            "Epoch 100/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4850\n",
            "Epoch 101/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5060\n",
            "Epoch 102/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.4750\n",
            "Epoch 103/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4760\n",
            "Epoch 104/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4900\n",
            "Epoch 105/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4960\n",
            "Epoch 106/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4950\n",
            "Epoch 107/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4690\n",
            "Epoch 108/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4940\n",
            "Epoch 109/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4510\n",
            "Epoch 110/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.4570\n",
            "Epoch 111/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4820\n",
            "Epoch 112/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.4770\n",
            "Epoch 113/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4740\n",
            "Epoch 114/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4660\n",
            "Epoch 115/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4690\n",
            "Epoch 116/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4830\n",
            "Epoch 117/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 118/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4990\n",
            "Epoch 119/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4750\n",
            "Epoch 120/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4980\n",
            "Epoch 121/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4740\n",
            "Epoch 122/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4920\n",
            "Epoch 123/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4640\n",
            "Epoch 124/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4660\n",
            "Epoch 125/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4800\n",
            "Epoch 126/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4960\n",
            "Epoch 127/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4760\n",
            "Epoch 128/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4920\n",
            "Epoch 129/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5100\n",
            "Epoch 130/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4840\n",
            "Epoch 131/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4780\n",
            "Epoch 132/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4760\n",
            "Epoch 133/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4800\n",
            "Epoch 134/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4740\n",
            "Epoch 135/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4670\n",
            "Epoch 136/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4590\n",
            "Epoch 137/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4840\n",
            "Epoch 138/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4610\n",
            "Epoch 139/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4810\n",
            "Epoch 140/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4610\n",
            "Epoch 141/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4630\n",
            "Epoch 142/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4790\n",
            "Epoch 143/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4790\n",
            "Epoch 144/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4650\n",
            "Epoch 145/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4990\n",
            "Epoch 146/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4570\n",
            "Epoch 147/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5110\n",
            "Epoch 148/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4880\n",
            "Epoch 149/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4500\n",
            "Epoch 150/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4700\n",
            "Epoch 151/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4620\n",
            "Epoch 152/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4990\n",
            "Epoch 153/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4870\n",
            "Epoch 154/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4810\n",
            "Epoch 155/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4780\n",
            "Epoch 156/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4680\n",
            "Epoch 157/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4990\n",
            "Epoch 158/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4940\n",
            "Epoch 159/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4710\n",
            "Epoch 160/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4880\n",
            "Epoch 161/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4770\n",
            "Epoch 162/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4920\n",
            "Epoch 163/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.4690\n",
            "Epoch 164/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4610\n",
            "Epoch 165/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4970\n",
            "Epoch 166/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4800\n",
            "Epoch 167/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.4930\n",
            "Epoch 168/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4690\n",
            "Epoch 169/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4880\n",
            "Epoch 170/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4850\n",
            "Epoch 171/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4980\n",
            "Epoch 172/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4770\n",
            "Epoch 173/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4730\n",
            "Epoch 174/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4950\n",
            "Epoch 175/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.4900\n",
            "Epoch 176/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4770\n",
            "Epoch 177/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4670\n",
            "Epoch 178/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4840\n",
            "Epoch 179/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4880\n",
            "Epoch 180/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4960\n",
            "Epoch 181/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4890\n",
            "Epoch 182/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4760\n",
            "Epoch 183/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5030\n",
            "Epoch 184/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4890\n",
            "Epoch 185/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4890\n",
            "Epoch 186/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4810\n",
            "Epoch 187/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4760\n",
            "Epoch 188/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4910\n",
            "Epoch 189/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5120\n",
            "Epoch 190/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4720\n",
            "Epoch 191/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4770\n",
            "Epoch 192/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4970\n",
            "Epoch 193/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4720\n",
            "Epoch 194/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4940\n",
            "Epoch 195/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4660\n",
            "Epoch 196/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4740\n",
            "Epoch 197/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4890\n",
            "Epoch 198/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4830\n",
            "Epoch 199/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5120\n",
            "Epoch 200/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4810\n",
            "Epoch 201/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.4590\n",
            "Epoch 202/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4820\n",
            "Epoch 203/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4550\n",
            "Epoch 204/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4860\n",
            "Epoch 205/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4710\n",
            "Epoch 206/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4820\n",
            "Epoch 207/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4600\n",
            "Epoch 208/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4610\n",
            "Epoch 209/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4650\n",
            "Epoch 210/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4910\n",
            "Epoch 211/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4960\n",
            "Epoch 212/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4780\n",
            "Epoch 213/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4800\n",
            "Epoch 214/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4950\n",
            "Epoch 215/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.4520\n",
            "Epoch 216/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4750\n",
            "Epoch 217/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4740\n",
            "Epoch 218/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4990\n",
            "Epoch 219/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4620\n",
            "Epoch 220/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4800\n",
            "Epoch 221/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4780\n",
            "Epoch 222/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4830\n",
            "Epoch 223/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4780\n",
            "Epoch 224/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4910\n",
            "Epoch 225/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5190\n",
            "Epoch 226/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4720\n",
            "Epoch 227/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4600\n",
            "Epoch 228/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4640\n",
            "Epoch 229/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4680\n",
            "Epoch 230/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4760\n",
            "Epoch 231/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5120\n",
            "Epoch 232/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4660\n",
            "Epoch 233/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4540\n",
            "Epoch 234/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4810\n",
            "Epoch 235/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4740\n",
            "Epoch 236/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4750\n",
            "Epoch 237/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5010\n",
            "Epoch 238/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4990\n",
            "Epoch 239/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4930\n",
            "Epoch 240/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4680\n",
            "Epoch 241/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4830\n",
            "Epoch 242/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4830\n",
            "Epoch 243/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.4970\n",
            "Epoch 244/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4920\n",
            "Epoch 245/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5010\n",
            "Epoch 246/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4560\n",
            "Epoch 247/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4820\n",
            "Epoch 248/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4960\n",
            "Epoch 249/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4810\n",
            "Epoch 250/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4640\n",
            "Epoch 251/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5140\n",
            "Epoch 252/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4710\n",
            "Epoch 253/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4760\n",
            "Epoch 254/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4950\n",
            "Epoch 255/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4900\n",
            "Epoch 256/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4920\n",
            "Epoch 257/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4880\n",
            "Epoch 258/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4710\n",
            "Epoch 259/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4760\n",
            "Epoch 260/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4880\n",
            "Epoch 261/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4870\n",
            "Epoch 262/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4790\n",
            "Epoch 263/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4510\n",
            "Epoch 264/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4880\n",
            "Epoch 265/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4340\n",
            "Epoch 266/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4950\n",
            "Epoch 267/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4660\n",
            "Epoch 268/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4840\n",
            "Epoch 269/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4850\n",
            "Epoch 270/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4950\n",
            "Epoch 271/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5120\n",
            "Epoch 272/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4770\n",
            "Epoch 273/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4640\n",
            "Epoch 274/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4710\n",
            "Epoch 275/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4620\n",
            "Epoch 276/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4850\n",
            "Epoch 277/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4750\n",
            "Epoch 278/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4930\n",
            "Epoch 279/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4830\n",
            "Epoch 280/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4750\n",
            "Epoch 281/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4940\n",
            "Epoch 282/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4660\n",
            "Epoch 283/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4500\n",
            "Epoch 284/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4820\n",
            "Epoch 285/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4940\n",
            "Epoch 286/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4680\n",
            "Epoch 287/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4820\n",
            "Epoch 288/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4670\n",
            "Epoch 289/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4980\n",
            "Epoch 290/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4750\n",
            "Epoch 291/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4770\n",
            "Epoch 292/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4800\n",
            "Epoch 293/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4800\n",
            "Epoch 294/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4750\n",
            "Epoch 295/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4930\n",
            "Epoch 296/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4880\n",
            "Epoch 297/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4980\n",
            "Epoch 298/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4880\n",
            "Epoch 299/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4900\n",
            "Epoch 300/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4790\n",
            "Epoch 301/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4720\n",
            "Epoch 302/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4920\n",
            "Epoch 303/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4770\n",
            "Epoch 304/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4850\n",
            "Epoch 305/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4900\n",
            "Epoch 306/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4810\n",
            "Epoch 307/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4470\n",
            "Epoch 308/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4640\n",
            "Epoch 309/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4820\n",
            "Epoch 310/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4890\n",
            "Epoch 311/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4600\n",
            "Epoch 312/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4740\n",
            "Epoch 313/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4640\n",
            "Epoch 314/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4760\n",
            "Epoch 315/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4760\n",
            "Epoch 316/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4870\n",
            "Epoch 317/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4850\n",
            "Epoch 318/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.4710\n",
            "Epoch 319/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5020\n",
            "Epoch 320/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4960\n",
            "Epoch 321/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4740\n",
            "Epoch 322/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4910\n",
            "Epoch 323/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4720\n",
            "Epoch 324/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.4660\n",
            "Epoch 325/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4840\n",
            "Epoch 326/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4810\n",
            "Epoch 327/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4790\n",
            "Epoch 328/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4770\n",
            "Epoch 329/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4800\n",
            "Epoch 330/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4790\n",
            "Epoch 331/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4880\n",
            "Epoch 332/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.5160\n",
            "Epoch 333/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4570\n",
            "Epoch 334/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.4930\n",
            "Epoch 335/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4700\n",
            "Epoch 336/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5260\n",
            "Epoch 337/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4940\n",
            "Epoch 338/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4850\n",
            "Epoch 339/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4880\n",
            "Epoch 340/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4680\n",
            "Epoch 341/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4750\n",
            "Epoch 342/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4910\n",
            "Epoch 343/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4850\n",
            "Epoch 344/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4890\n",
            "Epoch 345/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 346/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.4760\n",
            "Epoch 347/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4480\n",
            "Epoch 348/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4770\n",
            "Epoch 349/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4810\n",
            "Epoch 350/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4740\n",
            "Epoch 351/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4800\n",
            "Epoch 352/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.5050\n",
            "Epoch 353/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4840\n",
            "Epoch 354/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4800\n",
            "Epoch 355/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5060\n",
            "Epoch 356/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4610\n",
            "Epoch 357/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4980\n",
            "Epoch 358/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4570\n",
            "Epoch 359/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4890\n",
            "Epoch 360/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5030\n",
            "Epoch 361/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5010\n",
            "Epoch 362/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4900\n",
            "Epoch 363/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.4640\n",
            "Epoch 364/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5040\n",
            "Epoch 365/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4500\n",
            "Epoch 366/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4780\n",
            "Epoch 367/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4760\n",
            "Epoch 368/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4730\n",
            "Epoch 369/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.4510\n",
            "Epoch 370/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4710\n",
            "Epoch 371/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4710\n",
            "Epoch 372/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5040\n",
            "Epoch 373/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5010\n",
            "Epoch 374/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4620\n",
            "Epoch 375/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4850\n",
            "Epoch 376/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4770\n",
            "Epoch 377/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4580\n",
            "Epoch 378/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4590\n",
            "Epoch 379/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4690\n",
            "Epoch 380/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4870\n",
            "Epoch 381/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4670\n",
            "Epoch 382/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4940\n",
            "Epoch 383/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4980\n",
            "Epoch 384/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4620\n",
            "Epoch 385/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4800\n",
            "Epoch 386/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4890\n",
            "Epoch 387/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5010\n",
            "Epoch 388/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4750\n",
            "Epoch 389/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4820\n",
            "Epoch 390/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4850\n",
            "Epoch 391/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.5170\n",
            "Epoch 392/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4800\n",
            "Epoch 393/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4800\n",
            "Epoch 394/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4930\n",
            "Epoch 395/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4890\n",
            "Epoch 396/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5160\n",
            "Epoch 397/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4750\n",
            "Epoch 398/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4420\n",
            "Epoch 399/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.4630\n",
            "Epoch 400/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4780\n",
            "Epoch 401/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4640\n",
            "Epoch 402/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4810\n",
            "Epoch 403/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5030\n",
            "Epoch 404/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4860\n",
            "Epoch 405/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4750\n",
            "Epoch 406/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 407/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4830\n",
            "Epoch 408/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4880\n",
            "Epoch 409/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4890\n",
            "Epoch 410/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4940\n",
            "Epoch 411/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4800\n",
            "Epoch 412/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4770\n",
            "Epoch 413/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4770\n",
            "Epoch 414/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4970\n",
            "Epoch 415/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4900\n",
            "Epoch 416/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.4680\n",
            "Epoch 417/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 418/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4770\n",
            "Epoch 419/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4720\n",
            "Epoch 420/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4740\n",
            "Epoch 421/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4660\n",
            "Epoch 422/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4860\n",
            "Epoch 423/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4840\n",
            "Epoch 424/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.4810\n",
            "Epoch 425/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5060\n",
            "Epoch 426/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4590\n",
            "Epoch 427/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4890\n",
            "Epoch 428/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4970\n",
            "Epoch 429/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4730\n",
            "Epoch 430/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4800\n",
            "Epoch 431/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4630\n",
            "Epoch 432/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4930\n",
            "Epoch 433/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4950\n",
            "Epoch 434/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4570\n",
            "Epoch 435/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4900\n",
            "Epoch 436/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4840\n",
            "Epoch 437/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4570\n",
            "Epoch 438/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4770\n",
            "Epoch 439/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5160\n",
            "Epoch 440/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4510\n",
            "Epoch 441/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4530\n",
            "Epoch 442/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4720\n",
            "Epoch 443/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 444/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4720\n",
            "Epoch 445/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4950\n",
            "Epoch 446/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4750\n",
            "Epoch 447/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5110\n",
            "Epoch 448/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4940\n",
            "Epoch 449/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 450/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4670\n",
            "Epoch 451/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.4940\n",
            "Epoch 452/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4950\n",
            "Epoch 453/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4820\n",
            "Epoch 454/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5250\n",
            "Epoch 455/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4910\n",
            "Epoch 456/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5220\n",
            "Epoch 457/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4930\n",
            "Epoch 458/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4840\n",
            "Epoch 459/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4820\n",
            "Epoch 460/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.4560\n",
            "Epoch 461/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4930\n",
            "Epoch 462/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.4880\n",
            "Epoch 463/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4830\n",
            "Epoch 464/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4990\n",
            "Epoch 465/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4510\n",
            "Epoch 466/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4750\n",
            "Epoch 467/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4710\n",
            "Epoch 468/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4940\n",
            "Epoch 469/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4790\n",
            "Epoch 470/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4870\n",
            "Epoch 471/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4730\n",
            "Epoch 472/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4930\n",
            "Epoch 473/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4720\n",
            "Epoch 474/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4820\n",
            "Epoch 475/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4650\n",
            "Epoch 476/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4840\n",
            "Epoch 477/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4730\n",
            "Epoch 478/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.5060\n",
            "Epoch 479/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4710\n",
            "Epoch 480/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4660\n",
            "Epoch 481/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4770\n",
            "Epoch 482/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4580\n",
            "Epoch 483/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5060\n",
            "Epoch 484/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4590\n",
            "Epoch 485/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4560\n",
            "Epoch 486/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4690\n",
            "Epoch 487/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4610\n",
            "Epoch 488/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4950\n",
            "Epoch 489/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.5020\n",
            "Epoch 490/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4730\n",
            "Epoch 491/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4770\n",
            "Epoch 492/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.4920\n",
            "Epoch 493/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4650\n",
            "Epoch 494/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5020\n",
            "Epoch 495/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4930\n",
            "Epoch 496/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4890\n",
            "Epoch 497/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4920\n",
            "Epoch 498/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4670\n",
            "Epoch 499/500\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4800\n",
            "Epoch 500/500\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4890\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0c9701f150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16VCbDvsAbzA",
        "outputId": "4232b162-ff70-4b0a-c962-de27907db9b3"
      },
      "source": [
        "model_1.evaluate(X,y)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6933339238166809, 0.5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0FzfBr--wMH"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "model_2=tf.keras.Sequential([\n",
        "   tf.keras.layers.Dense(1),\n",
        "   tf.keras.layers.Dense(1)                          \n",
        "])\n",
        "\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iszTzHYf-wbo"
      },
      "source": [
        "model_2.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlOdeiLY-wnh",
        "outputId": "f0febf7f-c15c-4f96-8913-c7e8a064d18a"
      },
      "source": [
        "model_2.fit(X,y,epochs=100)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 1.8044 - accuracy: 0.5090\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.7235 - accuracy: 0.5030\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.7145 - accuracy: 0.4950\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.7078 - accuracy: 0.5010\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.7037 - accuracy: 0.5010\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.7008 - accuracy: 0.4960\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.7001 - accuracy: 0.4990\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6984 - accuracy: 0.4980\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6973 - accuracy: 0.4960\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6962 - accuracy: 0.4920\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6962 - accuracy: 0.4950\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.4980\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.4930\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6954 - accuracy: 0.4980\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.4900\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.5010\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5190\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4820\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5120\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5060\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5060\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4630\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.5130\n",
            "Epoch 24/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4710\n",
            "Epoch 25/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4730\n",
            "Epoch 26/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4920\n",
            "Epoch 27/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5080\n",
            "Epoch 28/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4510\n",
            "Epoch 29/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4830\n",
            "Epoch 30/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4940\n",
            "Epoch 31/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5340\n",
            "Epoch 32/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4940\n",
            "Epoch 33/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4750\n",
            "Epoch 34/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4910\n",
            "Epoch 35/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5150\n",
            "Epoch 36/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4680\n",
            "Epoch 37/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.5160\n",
            "Epoch 38/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4900\n",
            "Epoch 39/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4890\n",
            "Epoch 40/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.4640\n",
            "Epoch 41/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4900\n",
            "Epoch 42/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4990\n",
            "Epoch 43/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4860\n",
            "Epoch 44/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5130\n",
            "Epoch 45/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4890\n",
            "Epoch 46/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4900\n",
            "Epoch 47/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5090\n",
            "Epoch 48/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4930\n",
            "Epoch 49/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4830\n",
            "Epoch 50/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 51/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4960\n",
            "Epoch 52/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4980\n",
            "Epoch 53/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4720\n",
            "Epoch 54/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4910\n",
            "Epoch 55/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4970\n",
            "Epoch 56/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4870\n",
            "Epoch 57/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4870\n",
            "Epoch 58/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4870\n",
            "Epoch 59/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5130\n",
            "Epoch 60/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4920\n",
            "Epoch 61/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4950\n",
            "Epoch 62/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4950\n",
            "Epoch 63/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4860\n",
            "Epoch 64/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4810\n",
            "Epoch 65/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4980\n",
            "Epoch 66/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4910\n",
            "Epoch 67/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4950\n",
            "Epoch 68/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4960\n",
            "Epoch 69/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 70/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4780\n",
            "Epoch 71/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4970\n",
            "Epoch 72/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4800\n",
            "Epoch 73/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4840\n",
            "Epoch 74/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4900\n",
            "Epoch 75/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4940\n",
            "Epoch 76/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5040\n",
            "Epoch 77/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4910\n",
            "Epoch 78/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4860\n",
            "Epoch 79/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5020\n",
            "Epoch 80/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 81/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4820\n",
            "Epoch 82/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4920\n",
            "Epoch 83/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5120\n",
            "Epoch 84/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 85/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4830\n",
            "Epoch 86/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4830\n",
            "Epoch 87/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4880\n",
            "Epoch 88/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4860\n",
            "Epoch 89/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4910\n",
            "Epoch 90/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4960\n",
            "Epoch 91/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4970\n",
            "Epoch 92/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4910\n",
            "Epoch 93/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5040\n",
            "Epoch 94/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4750\n",
            "Epoch 95/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4840\n",
            "Epoch 96/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4690\n",
            "Epoch 97/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4970\n",
            "Epoch 98/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 99/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4980\n",
            "Epoch 100/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4690\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0c970284d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2RyEdO8-oCr",
        "outputId": "1c46cd97-7bdf-4f71-d74b-c0f2c9bbe70e"
      },
      "source": [
        "model_2.evaluate(X,y)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6933314800262451, 0.5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNL02hbe6M89"
      },
      "source": [
        " tf.random.set_seed(42)\n",
        "\n",
        " model_3=tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)                          \n",
        " ]\n",
        " )"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff4NXXSVIs7b"
      },
      "source": [
        "model_3.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"]\n",
        " )"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TSby6B3J4p9",
        "outputId": "f4ed585b-e9b6-4642-8484-0664a6f89f60"
      },
      "source": [
        "model_3.fit(X,y,epochs=100)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "32/32 [==============================] - 1s 1ms/step - loss: 2.9658 - accuracy: 0.4490\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.7229 - accuracy: 0.4390\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6971 - accuracy: 0.4700\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.4620\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4750\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4750\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5040\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.4980\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4880\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4480\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.4450\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.4890\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6956 - accuracy: 0.4920\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.5140\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.4590\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4820\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6975 - accuracy: 0.4950\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.4550\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.5330\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6956 - accuracy: 0.4560\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.4920\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.4350\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4990\n",
            "Epoch 24/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.4690\n",
            "Epoch 25/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6973 - accuracy: 0.4970\n",
            "Epoch 26/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6973 - accuracy: 0.4830\n",
            "Epoch 27/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.5040\n",
            "Epoch 28/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.4680\n",
            "Epoch 29/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6973 - accuracy: 0.4790\n",
            "Epoch 30/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6998 - accuracy: 0.4800\n",
            "Epoch 31/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.5030\n",
            "Epoch 32/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.4760\n",
            "Epoch 33/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.4570\n",
            "Epoch 34/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6973 - accuracy: 0.4800\n",
            "Epoch 35/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.5050\n",
            "Epoch 36/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.4680\n",
            "Epoch 37/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.4870\n",
            "Epoch 38/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6975 - accuracy: 0.4980\n",
            "Epoch 39/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.4690\n",
            "Epoch 40/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.4990\n",
            "Epoch 41/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6979 - accuracy: 0.4890\n",
            "Epoch 42/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.4700\n",
            "Epoch 43/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.5030\n",
            "Epoch 44/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.4830\n",
            "Epoch 45/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.5120\n",
            "Epoch 46/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.4730\n",
            "Epoch 47/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6974 - accuracy: 0.5170\n",
            "Epoch 48/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.4840\n",
            "Epoch 49/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.4870\n",
            "Epoch 50/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6972 - accuracy: 0.4610\n",
            "Epoch 51/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6980 - accuracy: 0.4800\n",
            "Epoch 52/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.5020\n",
            "Epoch 53/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.4940\n",
            "Epoch 54/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6993 - accuracy: 0.5020\n",
            "Epoch 55/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6953 - accuracy: 0.5220\n",
            "Epoch 56/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.4930\n",
            "Epoch 57/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6981 - accuracy: 0.4720\n",
            "Epoch 58/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.4980\n",
            "Epoch 59/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.7004 - accuracy: 0.4890\n",
            "Epoch 60/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.7011 - accuracy: 0.4870\n",
            "Epoch 61/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6996 - accuracy: 0.4680\n",
            "Epoch 62/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6965 - accuracy: 0.4980\n",
            "Epoch 63/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.4860\n",
            "Epoch 64/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.4940\n",
            "Epoch 65/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6996 - accuracy: 0.4810\n",
            "Epoch 66/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6965 - accuracy: 0.5010\n",
            "Epoch 67/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.4500\n",
            "Epoch 68/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.5020\n",
            "Epoch 69/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.5230\n",
            "Epoch 70/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.4680\n",
            "Epoch 71/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6975 - accuracy: 0.4650\n",
            "Epoch 72/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.5010\n",
            "Epoch 73/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6963 - accuracy: 0.4930\n",
            "Epoch 74/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.5130\n",
            "Epoch 75/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6963 - accuracy: 0.4980\n",
            "Epoch 76/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6980 - accuracy: 0.4850\n",
            "Epoch 77/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6971 - accuracy: 0.5020\n",
            "Epoch 78/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.4720\n",
            "Epoch 79/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.7009 - accuracy: 0.5110\n",
            "Epoch 80/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.4930\n",
            "Epoch 81/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6980 - accuracy: 0.5030\n",
            "Epoch 82/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.4830\n",
            "Epoch 83/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.7002 - accuracy: 0.4480\n",
            "Epoch 84/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.4970\n",
            "Epoch 85/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.4590\n",
            "Epoch 86/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.7002 - accuracy: 0.4900\n",
            "Epoch 87/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6977 - accuracy: 0.4550\n",
            "Epoch 88/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.4590\n",
            "Epoch 89/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.4750\n",
            "Epoch 90/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6981 - accuracy: 0.4620\n",
            "Epoch 91/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.4980\n",
            "Epoch 92/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.4760\n",
            "Epoch 93/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.4690\n",
            "Epoch 94/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.7005 - accuracy: 0.4800\n",
            "Epoch 95/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.4520\n",
            "Epoch 96/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.4790\n",
            "Epoch 97/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.4580\n",
            "Epoch 98/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.4800\n",
            "Epoch 99/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6976 - accuracy: 0.5090\n",
            "Epoch 100/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.4870\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0c966f4ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Xk8DIeqJ8nc",
        "outputId": "55b6424b-fb75-412c-9e84-437bd99b0884"
      },
      "source": [
        "model_3.evaluate(X,y)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6980 - accuracy: 0.5080\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6980254650115967, 0.5080000162124634]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ7vk2CsKCOZ"
      },
      "source": [
        "#madewithml"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhqGILZwKo_N"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "model_4=tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4,activation='relu'),\n",
        "    tf.keras.layers.Dense(4,activation='relu'),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "\n",
        "])"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiybbmcXKpCv"
      },
      "source": [
        "model_4.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_zOaSUsKpGO",
        "outputId": "6691fd38-b6fd-4447-bf68-7260a6bc96f6"
      },
      "source": [
        "model_4.fit(X,y,epochs=10)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0518 - accuracy: 0.9900\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0447 - accuracy: 0.9870\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0473 - accuracy: 0.9890\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0422 - accuracy: 0.9910\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0440 - accuracy: 0.9910\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0459 - accuracy: 0.9870\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0427 - accuracy: 0.9910\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0464 - accuracy: 0.9890\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0416 - accuracy: 0.9900\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0421 - accuracy: 0.9900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0c96bb3390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3dQIHVxe2y5",
        "outputId": "5ab304d1-ef04-4c30-8e6e-5f849515f65f"
      },
      "source": [
        "model_4.evaluate(X,y)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0444 - accuracy: 0.9880\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04437560215592384, 0.9879999756813049]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVXnrbvZgQdg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}